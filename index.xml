<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Kunal Kushwaha</title>
    <link>http://kunalkushwaha.github.io/</link>
    <description>Recent content on Kunal Kushwaha</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>Kunal Kushwaha</copyright>
    <lastBuildDate>Thu, 14 Jan 2016 12:45:10 +0900</lastBuildDate>
    <atom:link href="http://kunalkushwaha.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Tutorial: Getting started with docker machine and Swarm</title>
      <link>http://kunalkushwaha.github.io/2016/01/14/tutorial-getting-started-with-docker-machine-and-swarm/</link>
      <pubDate>Thu, 14 Jan 2016 12:45:10 +0900</pubDate>
      
      <guid>http://kunalkushwaha.github.io/2016/01/14/tutorial-getting-started-with-docker-machine-and-swarm/</guid>
      <description>

&lt;p&gt;&lt;a href=&#34;https://github.com/docker/machine&#34;&gt;Docker-machine&lt;/a&gt; is tool to create Docker hosts on computer, on cloud providers, and inside data center. It creates &lt;a href=&#34;https://docs.docker.com/machine/drivers/os-base/&#34;&gt;Linux based&lt;/a&gt; server, and installs and configures docker. It is also capable of configuring docker-swarm nodes.&lt;/p&gt;

&lt;p&gt;This blog, will explain stepwise walkthrough for docker host creation using docker-machine.&lt;/p&gt;

&lt;h2 id=&#34;installation:fce0df6d9ab4aa14b09a0b333f488e03&#34;&gt;Installation.&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;If you use Windows or Mac, Docker has already made awesome packaged installer for you &lt;a href=&#34;https://www.docker.com/products/docker-toolbox&#34;&gt;Docker-toolbox&lt;/a&gt;. Download and Install it.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;For Linux users, you can download docker-machine binaries from &lt;a href=&#34;https://github.com/docker/machine/releases&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;NOTE: &lt;i&gt; Linux users, do remember, you need to install docker client also on your machine.&lt;/i&gt;&lt;/p&gt;

&lt;h2 id=&#34;creation-of-docker-host-with-machine:fce0df6d9ab4aa14b09a0b333f488e03&#34;&gt;Creation of docker host with machine.&lt;/h2&gt;

&lt;p&gt;I will be using VirtualBox in this demo, but you can explore cloud options too.&lt;/p&gt;

&lt;p&gt;Docker host can be created with command &lt;code&gt;docker-machine create&lt;/code&gt;. Here &lt;code&gt;-d&lt;/code&gt; flags specifies driver-name. So command looks like as follows.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;$ docker-machine create -d &amp;lt;driver-name&amp;gt; &amp;lt;name-of-machine&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;This command does couple of things at backend such as
 - It downloads latest boot2docker image, if not locally available.
 - Create a machine with &lt;code&gt;name-of-machine&lt;/code&gt;
 - Creates ssh keys and copies to machine.
 - Installs &lt;code&gt;docker&lt;/code&gt;
 - Configures docker daemon at port 2376, so that docker daemon accessible at  &lt;code&gt;tcp://&amp;lt;HostIP&amp;gt;:2376&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Lets create our first host &lt;code&gt;testhost&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt; $ docker-machine create -d virtualbox testhost
 Running pre-create checks...
Creating machine...
(testhost) Copying C:\Users\kunal\.docker\machine\cache\boot2docker.iso to C:\Users\kunal\.docker\machine\machines\testhost\boot2docker.iso...
(testhost) Creating VirtualBox VM...
(testhost) Creating SSH key...
(testhost) Starting VM...
Waiting for machine to be running, this may take a few minutes...
Machine is running, waiting for SSH to be available...
Detecting operating system of created instance...
Detecting the provisioner...
Provisioning with boot2docker...
Copying certs to the local machine directory...
Copying certs to the remote machine...
Setting Docker configuration on the remote daemon...
Checking connection to Docker...
Docker is up and running!
To see how to connect Docker to this machine, run: C:\Program Files\Docker Toolbox\docker-machine.exe env testhost
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Here our docker host is ready for use. But wait! host is not same machine as your machine right? It is running inside Virtual Machine.
So how docker daemon is accessed remotely?&lt;/p&gt;

&lt;p&gt;Docker works on client-server model. Docker daemon is server and it can communicates though &lt;a href=&#34;https://docs.docker.com/engine/reference/api/docker_remote_api/&#34;&gt;REST API&amp;rsquo;s&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;i&gt; NOTE: &lt;code&gt;docker-machine create&lt;/code&gt; is most important command of docker-machine. Understanding various flags help you to get best of docker-machine. You must spend some time in understanding all &lt;a href=&#34;https://docs.docker.com/machine/reference/create/&#34;&gt;flags&lt;/a&gt; &lt;/i&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;To access docker host with docker client binary remotely, we need to export some environment variables.
Docker-machine provides a handy command for printing these variables and their values for us as shown below.&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;  $ docker-machine env testhost
  export DOCKER_TLS_VERIFY=&amp;quot;1&amp;quot;
  export DOCKER_HOST=&amp;quot;tcp://192.168.99.110:2376&amp;quot;
  export DOCKER_CERT_PATH=&amp;quot;C:\Users\kunal\.docker\machine\machines\testhost&amp;quot;
  export DOCKER_MACHINE_NAME=&amp;quot;testhost&amp;quot;
  # Run this command to configure your shell:
  # eval $(&amp;quot;C:\Program Files\Docker Toolbox\docker-machine.exe&amp;quot; env testhost)
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;To export all environment variable at once, simply run
&lt;code&gt;
$ eval $(docker-machine env testhost)
&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Now all docker commands will communicates with docker daemon of &lt;code&gt;testhost&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;  $ docker info
  Containers: 0
  Images: 0
  Server Version: 1.9.1
  Storage Driver: aufs
   Root Dir: /mnt/sda1/var/lib/docker/aufs
   Backing Filesystem: extfs
   Dirs: 0
   Dirperm1 Supported: true
  Execution Driver: native-0.2
  Logging Driver: json-file
  Kernel Version: 4.1.13-boot2docker
  Operating System: Boot2Docker 1.9.1 (TCL 6.4.1); master : cef800b - Fri Nov 20 19:33:59 UTC 2015
  CPUs: 1
  Total Memory: 996.2 MiB
  Name: testhost
  ID: 26MF:TVKB:JI7Q:TL4S:7RXM:U5CD:VHIR:W2NH:CUNZ:RGB3:C6GC:POBS
  Debug mode (server): true
   File Descriptors: 14
   Goroutines: 21
   System Time: 2016-01-07T07:09:51.081394779Z
   EventsListeners: 0
   Init SHA1:
   Init Path: /usr/local/bin/docker
   Docker Root Dir: /mnt/sda1/var/lib/docker
  Labels:
   provider=virtualbox
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Lets create our first docker container on this host.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;  $ docker run busybox sh
  Unable to find image &#39;busybox:latest&#39; locally
  latest: Pulling from library/busybox
  c00ef186408b: Pulling fs layer
  ac6a7980c6c2: Pulling fs layer
  ac6a7980c6c2: Verifying Checksum
  ac6a7980c6c2: Download complete
  c00ef186408b: Verifying Checksum
  c00ef186408b: Download complete
  c00ef186408b: Pull complete
  ac6a7980c6c2: Pull complete
  Digest: sha256:e4f93f6ed15a0cdd342f5aae387886fba0ab98af0a102da6276eaf24d6e6ade0
  Status: Downloaded newer image for busybox:latest
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;i&gt; NOTE: If you are one of user, who works behind proxy, then you may face problem like, your newly created docker host may not communicate with &lt;a href=&#34;https://hub.docker.com/&#34;&gt;docker-hub&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;To Fix that, you need to pass few environment flags at creation time as below.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;  $ docker-machine create -d virtualbox \
  --engine-env HTTP_PROXY=&amp;quot;http://example.com:8080&amp;quot; \
  --engine-env HTTPS_PROXY=&amp;quot;http://example.com:8080&amp;quot; \
  testhost
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/i&gt;&lt;/p&gt;

&lt;p&gt;So now we learnt how to create a docker host and run docker containers using docker-machine.
But Docker-machine not only lets you to create independent hosts, but also can put these host in one cluster!&lt;/p&gt;

&lt;p&gt;Isn&amp;rsquo;t it interesting?&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s see how we can build whole cluster of docker-hosts using docker-machine.&lt;/p&gt;

&lt;p&gt;Docker &lt;a href=&#34;https://www.docker.com/products/docker-swarm&#34;&gt;Swarm&lt;/a&gt; is native clustering solution for docker. Here with native means, Swarm understands and exports &lt;a href=&#34;https://docs.docker.com/swarm/swarm-api/&#34;&gt;all(almost)&lt;/a&gt; docker API&amp;rsquo;s. i.e. API for docker and docker swarm are same.
If one product/scripts works with docker, it will automatically work with swarm :)&lt;/p&gt;

&lt;h2 id=&#34;docker-swarm:fce0df6d9ab4aa14b09a0b333f488e03&#34;&gt;Docker Swarm&lt;/h2&gt;

&lt;p&gt;Docker swarm has three components.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Discovery Backend : Swarm requires a discovery backend, which is used by each node(agent) to discover the master.

&lt;ul&gt;
&lt;li&gt;Default discovery is provided by Docker Hub. (Not for production usage)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Master : Swarm master takes care of all scheduling logic and HA.&lt;/li&gt;
&lt;li&gt;Agent : These runs on each node and communicates with Swarm master.

&lt;ul&gt;
&lt;li&gt;All agent node must listen to the same network interface (TCP port).&lt;/li&gt;
&lt;li&gt;Each node runs a node agent that registers the referenced Docker daemon, monitors it, and updates the discovery backend with the node’s status&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In this demo, We will create a docker swarm consisting one Master and three agents including master.
Also, Consul will be used for discovery backend.&lt;/p&gt;

&lt;h3 id=&#34;discovery-backend-using-consul:fce0df6d9ab4aa14b09a0b333f488e03&#34;&gt;Discovery Backend using consul.&lt;/h3&gt;

&lt;p&gt;We will create a dedicated machine for consul, but running &lt;a href=&#34;https://www.consul.io/&#34;&gt;consul&lt;/a&gt; using docker is just one command task.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;  $ docker-machine create -d virtualbox \
     --engine-env HTTP_PROXY=&amp;quot;http://example.com:8080&amp;quot; \
     --engine-env HTTPS_PROXY=&amp;quot;http://example.com:8080&amp;quot; \
     swl-consul

$ docker $(docker-machine config swl-consul) run \
     -e &amp;quot;http_proxy=http://example.com:8080&amp;quot; \
     -e &amp;quot;https_proxy=http://example.com:8080&amp;quot; \
     --restart=&amp;quot;always&amp;quot; \
     -d -p &amp;quot;8500:8500&amp;quot; \
     -h &amp;quot;consul&amp;quot; \
     progrium/consul -server -bootstrap
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Check if consul container is created as expected.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;  $ docker-machine ls
  NAME         ACTIVE   DRIVER       STATE     URL                         SWARM   DOCKER   ERRORS
  swl-consul   -        virtualbox   Running   tcp://192.168.99.100:2376           v1.9.1

  $ eval $(docker-machine env swl-consul)

  $ docker ps
  CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                                                                            NAMES
  5357e85abcb5        progrium/consul     &amp;quot;/bin/start -server -&amp;quot;   16 minutes ago      Up 16 minutes       53/tcp, 53/udp, 8300-8302/tcp, 8400/tcp, 8301-8302/udp, 0.0.0.0:8500-&amp;gt;8500/tcp   goofy_aryabhata
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;creation-of-swarm-master:fce0df6d9ab4aa14b09a0b333f488e03&#34;&gt;Creation of Swarm Master.&lt;/h3&gt;

&lt;p&gt;In cluster, we will have one master and 2 agents. But master will also have agent, so practically we will have 3 agents.&lt;/p&gt;

&lt;p&gt;Docker machine helps to setup docker host with swarm in single command.&lt;/p&gt;

&lt;p&gt;Few highlights of docker machine provisioned swarm enabled host.
- Swarm master and agent runs as docker containers.
- Swarm manager bind on &amp;ldquo;3376&amp;rdquo; port, So to communicate with master &lt;code&gt;tcp://&amp;lt;IP:3376&amp;gt;&amp;gt;&lt;/code&gt; should be used.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;  $ docker-machine create \
  &amp;gt;    -d virtualbox \
  &amp;gt;    --swarm \
  &amp;gt;    --swarm-master \
  &amp;gt;    --swarm-discovery=consul://$(docker-machine ip swl-consul):8500 \
  &amp;gt;    --engine-env HTTP_PROXY=http://example.com:8080 \
  &amp;gt;    --engine-env HTTPS_PROXY=http://example.com:8080 \
  &amp;gt;    --engine-env NO_PROXY=192.168.99.100 \
  &amp;gt;    --engine-opt=&amp;quot;cluster-store=consul://$(docker-machine ip swl-consul):8500&amp;quot; \
  &amp;gt;    --engine-opt=&amp;quot;cluster-advertise=eth1:3376&amp;quot; \
  &amp;gt;    node1
  Running pre-create checks...
   .
   .
  (node1) Starting VM...
  Waiting for machine to be running, this may take a few minutes...
  Machine is running, waiting for SSH to be available...
  Detecting operating system of created instance...
  Detecting the provisioner...
  Provisioning with boot2docker...
  Copying certs to the local machine directory...
  Copying certs to the remote machine...
  Setting Docker configuration on the remote daemon...
  Configuring swarm...
  Checking connection to Docker...
  Docker is up and running!
  To see how to connect Docker to this machine, run: C:\Program Files\Docker Toolbox\docker-machine.exe env node1

  $ eval $(docker-machine env node1)

  $ docker ps
  CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS               NAMES
  7e644b71f606        swarm:latest        &amp;quot;/swarm join --advert&amp;quot;   19 seconds ago      Up 16 seconds                           swarm-agent
  58f2a4da438b        swarm:latest        &amp;quot;/swarm manage --tlsv&amp;quot;   22 seconds ago      Up 19 seconds                           swarm-agent-master
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;i&gt; NOTE: You may have seen &lt;code&gt;NO_PROXY&lt;/code&gt; is also set as environment variable.
This is to skip proxy for communicating with consul server &lt;/i&gt;&lt;/p&gt;

&lt;p&gt;Here,
- &lt;code&gt;--swarm&lt;/code&gt; indicates, swarm agent will be configured.
- &lt;code&gt;--swarm-master&lt;/code&gt; indicates, swarm master will be configured.
&lt;code&gt;--swarm-discovery&lt;/code&gt; sets the backend discovery for swarm.&lt;/p&gt;

&lt;p&gt;Here you go, we have our swarm master node up and running. Before communicating to swarm, let me remind you again.
- Swarm and docker talks in same API signature. But on our host, we have both docker daemon and swarm running.
- Our docker client can communicate with both, but we need to choose whom it has to talk.
  - To talk with docker daemon use &lt;code&gt;eval $(docker-machine env &amp;lt;host-name&amp;gt;)&lt;/code&gt;
  - To talk with swarm use &lt;code&gt;eval $(docker-machine env --swarm &amp;lt;host-name&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;So, since we want our docker client should communicate with swarm, we will add &lt;code&gt;--swarm&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;  $ eval $(docker-machine env --swarm node1)

  $ docker info
  Containers: 2
  Images: 1
  Role: primary
  Strategy: spread
  Filters: health, port, dependency, affinity, constraint
  Nodes: 1
   node1: 192.168.99.102:2376
    └ Status: Healthy
    └ Containers: 2
    └ Reserved CPUs: 0 / 1
    └ Reserved Memory: 0 B / 1.021 GiB
    └ Labels: executiondriver=native-0.2, kernelversion=4.1.13-boot2docker, operatingsystem=Boot2Docker 1.9.1 (TCL 6.4.1); master : cef800b - Fri Nov 20 19:33:59 UTC 2015, provider=virtualbox, storagedriver=aufs
  CPUs: 1
  Total Memory: 1.021 GiB
  Name: node1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now add two nodes with only agent.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;  $ docker-machine create \
  &amp;gt;    -d virtualbox \
  &amp;gt;    --swarm \
  &amp;gt;    --swarm-discovery=&amp;quot;consul://$(docker-machine ip swl-consul):8500&amp;quot; \
  &amp;gt;    --engine-env HTTP_PROXY=&amp;quot;http://example.com:8080&amp;quot; \
  &amp;gt;    --engine-env HTTPS_PROXY=&amp;quot;http://example.com:8080&amp;quot; \
  &amp;gt;    --engine-env NO_PROXY=&amp;quot;192.168.99.100&amp;quot; \
  &amp;gt;    --engine-opt=&amp;quot;cluster-store=consul://$(docker-machine ip swl-consul):8500&amp;quot; \
  &amp;gt;    --engine-opt=&amp;quot;cluster-advertise=eth1:3376&amp;quot; \  
  &amp;gt;    node3
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;Command for adding agent doesn&amp;rsquo;t requires &lt;code&gt;--swarm-master&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;cluster-advertise&lt;/code&gt; and &lt;code&gt;cluster-store&lt;/code&gt; are required for overlay networking also, Will be explained later.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;So after adding two more machines with swarm agent, we have 4 machines running as below.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;  $ docker-machine ls
  NAME         ACTIVE   DRIVER       STATE     URL                         SWARM            DOCKER   ERRORS
  node1        -        virtualbox   Running   tcp://192.168.99.102:2376   node1 (master)   v1.9.1
  node2        -        virtualbox   Running   tcp://192.168.99.103:2376   node1            v1.9.1
  node3        -        virtualbox   Running   tcp://192.168.99.104:2376   node1            v1.9.1
  swl-consul   -        virtualbox   Running   tcp://192.168.99.100:2376                    v1.9.1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Lets see information of our cluster.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;  $ eval $(docker-machine env --swarm node1)

  $ docker info
  Containers: 4
  Images: 3
  Role: primary
  Strategy: spread
  Filters: health, port, dependency, affinity, constraint
  Nodes: 3
   node1: 192.168.99.102:2376
    └ Status: Healthy
    └ Containers: 2
    └ Reserved CPUs: 0 / 1
    └ Reserved Memory: 0 B / 1.021 GiB
    └ Labels: executiondriver=native-0.2, kernelversion=4.1.13-boot2docker, operatingsystem=Boot2Docker 1.9.1 (TCL 6.4.1); master : cef800b - Fri Nov 20 19:33:59 UTC 2015, provider=virtualbox, storagedriver=aufs
   node2: 192.168.99.103:2376
    └ Status: Healthy
    └ Containers: 1
    └ Reserved CPUs: 0 / 1
    └ Reserved Memory: 0 B / 1.021 GiB
    └ Labels: executiondriver=native-0.2, kernelversion=4.1.13-boot2docker, operatingsystem=Boot2Docker 1.9.1 (TCL 6.4.1); master : cef800b - Fri Nov 20 19:33:59 UTC 2015, provider=virtualbox, storagedriver=aufs
   node3: 192.168.99.104:2376
    └ Status: Healthy
    └ Containers: 1
    └ Reserved CPUs: 0 / 1
    └ Reserved Memory: 0 B / 1.021 GiB
    └ Labels: executiondriver=native-0.2, kernelversion=4.1.13-boot2docker, operatingsystem=Boot2Docker 1.9.1 (TCL 6.4.1); master : cef800b - Fri Nov 20 19:33:59 UTC 2015, provider=virtualbox, storagedriver=aufs
  CPUs: 3
  Total Memory: 3.064 GiB
  Name: node1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Superb! we have three nodes running in our cluster.
This completes the swarm setup!!&lt;/p&gt;

&lt;h2 id=&#34;understanding-few-more-swarm-functionality:fce0df6d9ab4aa14b09a0b333f488e03&#34;&gt;Understanding few more Swarm functionality.&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;Strategy&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Currently &amp;ldquo;Spread&amp;rdquo; strategy is set. So the containers will be spread over all the hosts in cluster.&lt;/p&gt;

&lt;p&gt;e.g.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;  $ docker run -d -P -m 1G -e MYSQL_ROOT_PASSWORD=test123 --name db mysql
  57a1af46d72117306b833a28a219d3523e1531c98a19ef25cba00a7bc94c9645

  $ docker run -d -P -m 1G --name frontend nginx
  f40776d7c9f7583965263340c1542a09eb7cb881c53bcf18a290df0d6ce2fd51

  $ docker ps
  CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                                                         NAMES
  f40776d7c9f7        nginx               &amp;quot;nginx -g &#39;daemon off&amp;quot;   4 seconds ago       Up 4 seconds        192.168.99.103:32770-&amp;gt;80/tcp, 192.168.99.103:32769-&amp;gt;443/tcp   node2/frontend
  57a1af46d721        mysql               &amp;quot;/entrypoint.sh mysql&amp;quot;   3 minutes ago       Up 3 minutes        192.168.99.104:32769-&amp;gt;3306/tcp                                node3/db
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;Here node3 have &lt;code&gt;db&lt;/code&gt; and node2 have &lt;code&gt;frontend&lt;/code&gt; container.&lt;/li&gt;
&lt;li&gt;If two nodes have the same amount of available RAM and CPUs, the spread strategy prefers the node with least containers.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Other available strategies are BinPack and Random.
- BinPack tries to pack all possible containers on single node first and so on.
- If two nodes have the same amount of available RAM and CPUs, the binpack strategy prefers the node with most containers.&lt;/p&gt;

&lt;p&gt;&lt;i&gt;Things to Try:
- Create swarm with BinPack and create multiple containers to see the behavior. &lt;/i&gt;&lt;/p&gt;

&lt;h3 id=&#34;filters:fce0df6d9ab4aa14b09a0b333f488e03&#34;&gt;Filters&lt;/h3&gt;

&lt;p&gt;Filters tell Docker Swarm scheduler which nodes to use when creating and running a container.&lt;/p&gt;

&lt;p&gt;Filters are divided into two categories, node filters and container configuration filters.
- Node filters operate on characteristics of the Docker host or on the configuration of the Docker daemon.
- Container configuration filters operate on characteristics of containers, or on the availability of images on a host.
- Each filter has a name that identifies it.&lt;/p&gt;

&lt;p&gt;The node filters are:
  - constraint
  - health&lt;/p&gt;

&lt;p&gt;The container configuration filters are:
  - affinity
  - dependency
  - port&lt;/p&gt;

&lt;p&gt;When you start a Swarm manager with the swarm manage command, all the filters are enabled.
If you want to limit the filters available to your Swarm, specify a subset of filters by passing the &lt;code&gt;--filter&lt;/code&gt; flag and the name:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ swarm manage --filter=health --filter=dependency
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In case of docker machine, while provisioning &lt;code&gt;--swarm-opt&lt;/code&gt; can be used to set filters.&lt;/p&gt;

&lt;h4 id=&#34;use-a-constraint-filter:fce0df6d9ab4aa14b09a0b333f488e03&#34;&gt;Use a constraint filter&lt;/h4&gt;

&lt;p&gt;Node constraints can refer to Docker’s default tags or to custom labels. Default tags are sourced from docker info. Often, they relate to properties of the Docker host. Currently, the dafult tags include:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;node to refer to the node by ID or name&lt;/li&gt;
&lt;li&gt;storagedriver&lt;/li&gt;
&lt;li&gt;executiondriver&lt;/li&gt;
&lt;li&gt;kernelversion&lt;/li&gt;
&lt;li&gt;operatingsystem&lt;/li&gt;
&lt;li&gt;Custom node labels can be applied while provisioning docker machine.

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;--engine-label&lt;/code&gt; can be used for setting custom label.&lt;/li&gt;
&lt;li&gt;custom label like &lt;code&gt;environment&lt;/code&gt;, &lt;code&gt;storage&lt;/code&gt; etc are helpful.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Since we have all labels same except node name, we will try creating new container using node-name constraint.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker run -itd -e constraint:node==node3 --name test1 ubuntu
ae4013d014931e43cd5342a625f6b549a8c920cb146b1371a7226359a4bcf014

$ docker run -itd -e constraint:node==node3 --name test2 ubuntu
a6b371773e1a2609122ca68df00d1e03ee274ba3db504d3942c301f8e2c45504

$ docker ps
CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES
a6b371773e1a        ubuntu              &amp;quot;/bin/bash&amp;quot;         3 seconds ago       Up 2 seconds                            node3/test2
ae4013d01493        ubuntu              &amp;quot;/bin/bash&amp;quot;         19 seconds ago      Up 18 seconds                           node3/test1
934501aed30f        ubuntu              &amp;quot;/bin/bash&amp;quot;         19 hours ago        Up 2 hours                              node3/n4
30358292be89        ubuntu              &amp;quot;/bin/bash&amp;quot;         19 hours ago        Up 19 hours                             node1/n3
6a13aa3eca8b        ubuntu              &amp;quot;/bin/bash&amp;quot;         21 hours ago        Up 21 hours                             node2/n1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Similarly other filters can be used. While using filters the syntax to use in &lt;code&gt;docker run&lt;/code&gt; is as below.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;- ``-e &amp;lt;filter-name&amp;gt;:&amp;lt;key&amp;gt;&amp;lt;operator&amp;gt;&amp;lt;value&amp;gt;``
- Here operator used are  ``==`` , ``!=`` &amp;amp; ``~``
- For ``==`` &amp;amp; ``!=``, exact match is found.
  - If nothing satisfies the condition, it does schedule container.
- ``~`` is for soft condition. i.e. if nothing matches, it ignores the condition and use default scheduler.
- Here value can contain any valid regex (https://github.com/google/re2/wiki/Syntax)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Hope this article will be helpful in getting started with docker-machine and swarm :)&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Understanding Golang Interfaces</title>
      <link>http://kunalkushwaha.github.io/2015/09/11/understanding-golang-interfaces/</link>
      <pubDate>Fri, 11 Sep 2015 15:14:46 +0900</pubDate>
      
      <guid>http://kunalkushwaha.github.io/2015/09/11/understanding-golang-interfaces/</guid>
      <description>

&lt;p&gt;Even after writing Go code for a while, there have been couple of time, when I get confused about Interfaces in golang.
So I think, it may help people, who have started with Golang, or don&amp;rsquo;t use much Interfaces in there code.&lt;/p&gt;

&lt;h3 id=&#34;interfaces:8e8f150f0261927c23fb2a377a40072b&#34;&gt;Interfaces&lt;/h3&gt;

&lt;p&gt;By definition, Interfaces are named collections of method signatures. But usage of Interfaces in go is little confusing as it is used a in context of data type also and defining the behavior of methods also.&lt;/p&gt;

&lt;p&gt;Lets try to understand each of them.&lt;/p&gt;

&lt;h3 id=&#34;1-interface-interface-as-data-type:8e8f150f0261927c23fb2a377a40072b&#34;&gt;1. interface{} , interface as data-type&lt;/h3&gt;

&lt;p&gt;This is commonly mistaken as ( void type of C/C++), But it&amp;rsquo;s not! It still holds its property from the above definition.
Since, &lt;code&gt;interface{}&lt;/code&gt; is empty interface i.e. No methods associated with it, all data type satisfy the behavior and hence, all data types can be passed/assigned to &lt;code&gt;interface{}&lt;/code&gt; type.&lt;/p&gt;

&lt;p&gt;Lets take a example,&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-golang&#34;&gt;
type Stack struct {
       data []interface{}
}

func NewStack() *Stack {
	s := Stack{data: make([]interface{},0)}
	return &amp;amp;s
}

func (s *Stack) Push(data interface{}) {
	s.data = append(s.data, data)
}

func (s *Stack) Pop() interface{} {
	if len(s.data) == 0 {
		return nil
	}
	data := s.data[len(s.data) -1]
	s.data = s.data[0:len(s.data)-1]
	return data
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To use the above stack, a simple example shows retrieval of values from interface type.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-golang&#34;&gt;s := NewStack()
s.Push(10)
s.Push(&amp;quot;Hello&amp;quot;)
obj1 := s.Pop()
obj2 = s.Pop()
// To retrieve int value, use type assertion.
elem1 := obj.(string)
elem2 := obj.(int)

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Here are few things needs to be understood about interfaces to be used as type.
 - Whenever variables of any datatype is assigned to interface type, it is converted into interface type and stored.
     - So properties of original data-type cannot be retrieved until, it is converted again back to original data-type.
 - conversion to data-type from interfaces cannot be achieved using typecasting, Here it required, &lt;a href=&#34;http://golang.org/ref/spec#Type_assertions&#34;&gt;type assertion&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;So use interface{}, wherever you wish to add generic data-type and remember at retrieval time, use type assertion!&lt;/p&gt;

&lt;h3 id=&#34;2-interface-as-set-of-methods:8e8f150f0261927c23fb2a377a40072b&#34;&gt;2. Interface as set of methods.&lt;/h3&gt;

&lt;p&gt;Unlike above type, here interface have some function prototype.&lt;/p&gt;

&lt;p&gt;If you come from &amp;ldquo;C/C++&amp;rdquo; background, you can relate it with function pointers or abstract functions/pure virtual functions. These functions don&amp;rsquo;t have any implementation.&lt;/p&gt;

&lt;p&gt;But, to implement these functions, no need to inherit in structs or assign to function pointers.&lt;/p&gt;

&lt;p&gt;In Go, if some structs or functions have same behavior as of interface, it automatically can be used in interface. Here behavior mean, all functions in interface should be implemented with same signature of functions as of interface.&lt;/p&gt;

&lt;p&gt;Lets take a simple example.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-golang&#34;&gt;type Plugin interface {
    Execute(string, int) bool
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Here, a Plugin interface is defined with one function. Any Structure, which have this one function, will automatically implements the interface.&lt;/p&gt;

&lt;p&gt;i.e. Any structure, which has same behavior means the Plugin interface can represent that structure. No explicitly need to show via any keyword like implement or inherit.&lt;/p&gt;

&lt;p&gt;I feel, it is very simple approach to build OOP design. Such simple approaches, to create design patterns, make Go even more interesting.&lt;/p&gt;

&lt;p&gt;Lets see examples which explains the behavior of interfaces&lt;/p&gt;

&lt;h3 id=&#34;1-example-1:8e8f150f0261927c23fb2a377a40072b&#34;&gt;1. Example #1&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-golang&#34;&gt; type aPlugin struct {
     name string
 }

 func (p aPlugin) Execute(name string, count int) bool {
     fmt.Println(&amp;quot;aPlugin executing&amp;quot;, name, count)
     return 0
 }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Here, structure &lt;code&gt;aPlugin&lt;/code&gt; have exactly same function as of &lt;code&gt;Plugin&lt;/code&gt; interface, so this &lt;code&gt;aPlugin&lt;/code&gt; can be assigned to Plugin interface.&lt;/p&gt;

&lt;p&gt;So main function will look like this.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-golang&#34;&gt; func main() {
    // Create a Plugin array
    obj := []Plugin{aPlugin{}, bPlugin{}}
    obj[0].Execute(&amp;quot;Hello&amp;quot;, 1)
    obj[1].Execute(&amp;quot;World&amp;quot;, 2)
 }

 $ go run main.go
 aPlugin executing Hello 1
 bPLugin executing World 2
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;2-example-2:8e8f150f0261927c23fb2a377a40072b&#34;&gt;2. Example #2&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-golang&#34;&gt; type bPlugin struct {
     name string
 }

 func (p bPlugin) Execute(name string, count int) bool {
     fmt.Println(&amp;quot;bPlugin executing&amp;quot;, name, count)
     return 0
 }

 func (p bPlugin) DumpInfo() {
     fmt.Println(p.name)
 }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Here, another structure &lt;code&gt;bPlugin&lt;/code&gt; have one additional function then of &lt;code&gt;Plugin&lt;/code&gt; interface. So this &lt;code&gt;bPlugin&lt;/code&gt; can be assigned to Plugin interface.&lt;/p&gt;

&lt;p&gt;Only, if it is assigned to Plugin object, the additional function DumpInfo() cannot be invoked from Plugin object.
    - So a Structure can have additional functions, data members and still it can assigned to interface object.&lt;/p&gt;

&lt;h3 id=&#34;3-example-3:8e8f150f0261927c23fb2a377a40072b&#34;&gt;3. Example #3&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-golang&#34;&gt; type cPlugin struct {
     name string
 }

 func (p cPlugin) Execute() bool {
     fmt.Println(&amp;quot;cPlugin executing&amp;quot;)
     return 0
 }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Here, structure &lt;code&gt;cPlugin&lt;/code&gt; have function with same name &lt;code&gt;Execute&lt;/code&gt;, but with different signatures. So cPlugin object cannot be assigned to &lt;code&gt;Plugin&lt;/code&gt; object.&lt;/p&gt;

&lt;p&gt;go compiler will raise error if it is tried to do so.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-golang&#34;&gt;obj := []Plugin{aPlugin{}, bPlugin{}, cPlugin{}}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt; $ go run main.go
 ./main.go:22: cannot use cPlugin literal (type cPlugin) as type Plugin in array element:
        cPlugin does not implement Plugin (wrong type for Execute method)
                have Execute() bool
                want Execute(string, int) bool

&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;how-should-these-interfaces-should-be-used:8e8f150f0261927c23fb2a377a40072b&#34;&gt;How should these interfaces should be used.&lt;/h2&gt;

&lt;p&gt;Interfaces are one of most important building blocks of golang. Also, its usage make golang as language very simpler to use.
for example, you can look into &lt;a href=&#34;http://golang.org/src/io/io.go&#34;&gt;&amp;ldquo;io&amp;rdquo; package&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;If you implement any kind of framework or as simple as muti-platform program, where you wish functionalities, differ for each OS, interfaces are perfect candidates to use.&lt;/p&gt;

&lt;p&gt;I hope this blog would have helped to understand the interfaces in Golang.
Please comment in case you have any feedback.&lt;/p&gt;

&lt;p&gt;Happy Coding :)&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Conditional compilation in golang</title>
      <link>http://kunalkushwaha.github.io/2015/07/24/conditional-compilation-in-golang/</link>
      <pubDate>Fri, 24 Jul 2015 22:21:27 +0900</pubDate>
      
      <guid>http://kunalkushwaha.github.io/2015/07/24/conditional-compilation-in-golang/</guid>
      <description>

&lt;h2 id=&#34;conditional-compiling-in-golang:2d62b9b37d02354b93f9e4e4f4d7ca80&#34;&gt;Conditional compiling in golang.&lt;/h2&gt;

&lt;p&gt;While hacking around experimental builds of docker, I learned about conditional compiling in golang.
As any project grew or ported to multiple architecture/platforms  the need of conditional compiling is obvious.&lt;/p&gt;

&lt;p&gt;Unlike C golang, do not have macros. Golang make use of build tags to achieve this.&lt;/p&gt;

&lt;h4 id=&#34;build-tags:2d62b9b37d02354b93f9e4e4f4d7ca80&#34;&gt;Build Tags:&lt;/h4&gt;

&lt;p&gt;Build tags are basically annotation in source code. generally it is first line of file, where build tags are defined.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;// +build &amp;lt;tags&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;These tags are searched by &lt;code&gt;go build&lt;/code&gt; tool before passing to go compiler. These tags can be passed while go build command like&lt;/p&gt;

&lt;p&gt;&lt;code&gt;$ go build -tags &amp;lt;tags&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Here are few points to remember regarding tags.
- Tags specifies architecture and platforms are special. i.e. No need to pass such tags, &lt;code&gt;go build&lt;/code&gt; is smart enough to pass them.
    - e.g. linux, windows, darwin, 386, arch etc
- Tags can be passed with negation i.e. !&lt;tag&gt;
- A blank line must be present between build tags and code, else that line will be ignored.
- OR condition for tags can be specified with space.
- AND condition can be specified with &lt;code&gt;,&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;If some tag is defined in file and is not passed in &lt;code&gt;go build&lt;/code&gt;` command, it will be ignored.&lt;/p&gt;

&lt;p&gt;Lets see this with example with custom tag.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Here we will take three files&lt;/li&gt;
&lt;li&gt;main.go&lt;/li&gt;
&lt;li&gt;include.go&lt;/li&gt;
&lt;li&gt;exclude.go&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;○ cat main.go
package main

import (
&amp;quot;fmt&amp;quot;
)

func init() {
        fmt.Println(&amp;quot;Hello from Main init()&amp;quot;)
}


func main() {
        fmt.Println(&amp;quot;Hello from main&amp;quot;)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;
○ cat include.go

package main

import &amp;quot;fmt&amp;quot;

func init() {
        fmt.Println(&amp;quot;Hello from IncludeInit()&amp;quot;)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;○ cat exclude.go
// +build exclude

package main

import &amp;quot;fmt&amp;quot;

func init(){
        fmt.Println(&amp;quot;Hello from exclude&amp;quot;)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As you can see, here exclude file has build tag of &lt;code&gt;exclude&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Now if do &lt;code&gt;go build&lt;/code&gt;, It will not compile exclude.go.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;○ go build

○ ./temp
Hello from IncludeInit()
Hello from Main init()
Hello from main
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now let try using buildtag exclude.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;○ go build -tags exclude

○ ./temp
Hello from exclude
Hello from IncludeInit()
Hello from Main init()
Hello from main
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You can see now, the exclude.go is part of binary.&lt;/p&gt;

&lt;p&gt;One more interesting thing with golang is &lt;code&gt;go list&lt;/code&gt; tool.
Using the &lt;code&gt;go list&lt;/code&gt;, without compiling, you can see which files will be compiled, with given gotags or default.&lt;/p&gt;

&lt;p&gt;I found &lt;code&gt;go list --help&lt;/code&gt; not great, but the summary of this tool is a go template can be used to check the list of files that will be included in the build.
A simple example as below will help you to understand better.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;○ go list -f &#39;{{.GoFiles}}&#39; --tags exclude
[exclude.go include.go main.go]

○ go list -f &#39;{{.GoFiles}}&#39;
[include.go main.go]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As you can see, if exclude tag is not used, only include.go and main.go files are used.&lt;/p&gt;

&lt;h4 id=&#34;so-it-that-all-about-conditional-compiling-in-golang:2d62b9b37d02354b93f9e4e4f4d7ca80&#34;&gt;So it that all about conditional compiling in golang?&lt;/h4&gt;

&lt;p&gt;No, There is even simpler method available too :-) and it is file-name suffixes.&lt;/p&gt;

&lt;p&gt;In golang, there are few go environment variables defined.
GOOS and GOARCH are two of such.
- GOOS defines the current OS
- GOARCH defines the current machine architecture.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;go build&lt;/code&gt; matches value of these two environment variables in filename and if it matches then only include for compiling.&lt;/p&gt;

&lt;p&gt;So by naming files like &lt;code&gt;exclude_linux.go&lt;/code&gt;, it will be included only if compiled in linux system.
&lt;code&gt;exclude_linux_amd64.go&lt;/code&gt; will ensure, it will be inlcuded only if OS is linux and architecture of system in 64 bit.&lt;/p&gt;

&lt;p&gt;You may try these combination.&lt;/p&gt;

&lt;h4 id=&#34;which-one-should-be-used:2d62b9b37d02354b93f9e4e4f4d7ca80&#34;&gt;Which one should be used?&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;For custom tags build tags are the only options.&lt;/li&gt;
&lt;li&gt;For platform and architecture specific, if you plan to use cross build on one systems, build tags will be preferable.&lt;/li&gt;
&lt;li&gt;Also, if same file does work for multiple platforms, build tags will be better choice.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For rest, file sufixes can be used.&lt;/p&gt;

&lt;p&gt;Hope this info will be useful.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Container Virtualization and its building blocks</title>
      <link>http://kunalkushwaha.github.io/2015/07/04/container-virtualization/</link>
      <pubDate>Sat, 04 Jul 2015 20:25:44 +0900</pubDate>
      
      <guid>http://kunalkushwaha.github.io/2015/07/04/container-virtualization/</guid>
      <description>

&lt;p&gt;Since 2014, Linux containers have become buzz word in Cloud Infrastructure. Almost all, from Big corporations to startups, all have started using it. Huge credit goes to &lt;a href=&#34;www.docker.com&#34;&gt;Docker&lt;/a&gt; for making using containers so easy to use.&lt;/p&gt;

&lt;p&gt;Linux Containers are there in Linux systems for alomst decade old, But making them work, was not so easy, and generally required linux admin experts for doing same. Few Solution as linux containers like FreeBSD Jails, LXC, openVZ, Solaris Zones etc exists for quite some time.&lt;/p&gt;

&lt;p&gt;These are also known as OS level Virtualization.
To understand other type of virtualization please read &lt;a href=&#34;http://kunalkushwaha.github.io/post/Layman-guide-to-Platform-Virtualization&#34;&gt;Layman guide to Platform virtualization&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;operating-system-level-virtualization:b9f02760c1e2afe4297fc7674428ef9f&#34;&gt;Operating System level Virtualization&lt;/h2&gt;

&lt;p&gt;Quoting below from Wikipedia, I it explains beautifully in technical and yet not too complex.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;OS level Virtualization is a server virtualization method where the kernel of an operating system allows for multiple isolated user space instances, instead of just one. Such instances (often called containers, virtualization engines (VE), virtual private servers (VPS), or jails) may look and feel like a real server from the point of view of its owners and users.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;In simple words, it allows to run multiple rootfs (user-space) simultaneously and all running rootfs have their own view of filesystem and devices. So they are not aware of each others and resource usage can be configured.&lt;/p&gt;

&lt;p&gt;Sounds similar to virtual Machines? Yes it is!&lt;/p&gt;

&lt;h4 id=&#34;how-this-isolation-is-achieved:b9f02760c1e2afe4297fc7674428ef9f&#34;&gt;How this isolation is achieved?&lt;/h4&gt;

&lt;p&gt;This isolation is achieved using linux features like namespaces, cgroups and chroot. To understand details we need to first understand each of them.&lt;/p&gt;

&lt;h4 id=&#34;namespaces:b9f02760c1e2afe4297fc7674428ef9f&#34;&gt;Namespaces&lt;/h4&gt;

&lt;p&gt;Namespace wraps a particular global system resource in an abstraction that makes it appear to the processes within the namespace that they have their own isolated instance of the global resource.&lt;/p&gt;

&lt;p&gt;Currently, Linux implements six different types of namespaces&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;h5 id=&#34;mount-namespaces-clone-newns:b9f02760c1e2afe4297fc7674428ef9f&#34;&gt;Mount namespaces (CLONE_NEWNS)&lt;/h5&gt;

&lt;p&gt;This isolate the set of filesystem mount points seen by a group of processes. Thus, processes in different mount namespaces can have different views of the filesystem hierarchy. With the addition of mount namespaces, the mount() and umount() system calls ceased operating on a global set of mount points visible to all processes on the system and instead performed operations that affected just the mount namespace associated with the calling process.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;This is also an alternative to chroot system call.&lt;/li&gt;
&lt;li&gt;This is supported since Linux 2.4.19&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;h5 id=&#34;uts-namespaces-clone-newuts:b9f02760c1e2afe4297fc7674428ef9f&#34;&gt;UTS namespaces (CLONE_NEWUTS)&lt;/h5&gt;

&lt;p&gt;This isolate two system identifiers—nodename and domainname—returned by the uname() system call; the names are set using the sethostname() and setdomainname() system calls.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;In the context of containers, the UTS namespaces feature allows each container to have its own hostname and NIS domain name. This can be useful for initialization and configuration scripts that tailor their actions based on these names.&lt;/li&gt;
&lt;li&gt;This is supported in Linux kernel since  Linux 2.6.19.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;h5 id=&#34;ipc-namespaces-clone-newipc:b9f02760c1e2afe4297fc7674428ef9f&#34;&gt;IPC namespaces (CLONE_NEWIPC)&lt;/h5&gt;

&lt;p&gt;This isolate certain interprocess communication (IPC) resources, namely, System V IPC objects and (since Linux 2.6.30) POSIX message queues.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;The common characteristic of these IPC mechanisms is that IPC objects are identified by mechanisms other than filesystem pathnames. Each IPC namespace has its own set of System V IPC identifiers and its own POSIX message queue filesystem.&lt;/li&gt;
&lt;li&gt;This is supported in Linux kernel since Linux 2.6.19&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;h5 id=&#34;pid-namespaces-clone-newpid:b9f02760c1e2afe4297fc7674428ef9f&#34;&gt;PID namespaces (CLONE_NEWPID)&lt;/h5&gt;

&lt;p&gt;This isolate the process ID number space. In other words, processes in different PID namespaces can have the same PID.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;This helps migrating containers between hosts while keeping the same process IDs for the processes inside the container.&lt;/li&gt;
&lt;li&gt;PID namespaces also allow each container to have its own init (PID 1), the &amp;ldquo;ancestor of all processes&amp;rdquo; that manages various system initialization tasks and reaps orphaned child processes when they terminate.&lt;/li&gt;
&lt;li&gt;This is supported since Linux 2.6.24&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;h5 id=&#34;network-namespaces-clone-newnet:b9f02760c1e2afe4297fc7674428ef9f&#34;&gt;Network namespaces (CLONE_NEWNET)&lt;/h5&gt;

&lt;p&gt;This provide isolation of the system resources associated with networking. Thus, each network namespace has its own network devices, IP addresses, IP routing tables, /proc/net directory, port numbers, and so on.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Network namespaces make containers useful from a networking perspective: each container can have its own (virtual) network device and its own applications that bind to the per-namespace port number space.&lt;/li&gt;
&lt;li&gt;started in Linux 2.4.19 2.6.24 and largely completed by about Linux 2.6.29&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;h5 id=&#34;user-namespaces-clone-newuser:b9f02760c1e2afe4297fc7674428ef9f&#34;&gt;User namespaces (CLONE_NEWUSER)&lt;/h5&gt;

&lt;p&gt;This isolate the user and group ID number spaces. In other words, a process&amp;rsquo;s user and group IDs can be different inside and outside a user namespace.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;The most interesting case here is that a process can have a normal unprivileged user ID outside a user namespace while at the same time having a user ID of 0 inside the namespace. This means that the process has full root privileges for operations inside the user namespace, but is unprivileged for operations outside the namespace.&lt;/li&gt;
&lt;li&gt;This was partially supported since Linux 2.6.23 and completed in Linux 3.8.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&#34;control-groups-a-k-a-cgroups:b9f02760c1e2afe4297fc7674428ef9f&#34;&gt;Control groups a.k.a. cgroups&lt;/h4&gt;

&lt;p&gt;Cgroups allow you to allocate resources—such as CPU time, system memory, network bandwidth, or combinations of these resources—among user-defined groups of tasks (processes) running on a system.
  - One can configure cgroups, deny cgroups access to certain resources, and even reconfigure cgroups dynamically on a running system.
  - The cgconfig (control group config) service can be configured to start up at boot time and reestablish your predefined cgroups, thus making them persistent across reboots.
  - By using cgroups, we gain fine-grained control over allocating, prioritizing, denying, managing, and monitoring system resources. Hardware resources can be appropriately divided up among tasks and users, increasing overall efficiency.
  - These are like process, hierarchical in nature i.e. child cgroups inherit certain attributes from their parent cgroup.&lt;/p&gt;

&lt;p&gt;Follwing resources are supported currently in cgroups.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;blkio — this subsystem sets limits on input/output access to and from block devices such as physical drives (disk, solid state, USB, etc.).&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;cpu — this subsystem uses the scheduler to provide cgroup tasks access to the CPU.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;cpuacct — this subsystem generates automatic reports on CPU resources used by tasks in a cgroup.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;cpuset — this subsystem assigns individual CPUs (on a multicore system) and memory nodes to tasks in a cgroup.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;devices — this subsystem allows or denies access to devices by tasks in a cgroup.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;freezer — this subsystem suspends or resumes tasks in a cgroup.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;memory — this subsystem sets limits on memory use by tasks in a cgroup, and generates automatic reports on memory resources used by those tasks.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;net_cls — this subsystem tags network packets with a class identifier (classid) that allows the Linux traffic controller (tc) to identify packets originating from a particular cgroup task.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;net_prio — this subsystem provides a way to dynamically set the priority of network traffic per network interface.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;ns — the namespace subsystem.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For details you may refer : &lt;a href=&#34;https://www.kernel.org/doc/Documentation/cgroups/cgroups.txt&#34;&gt;https://www.kernel.org/doc/Documentation/cgroups/cgroups.txt&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;so-how-these-helps-in-containers:b9f02760c1e2afe4297fc7674428ef9f&#34;&gt;So how these helps in containers?&lt;/h2&gt;

&lt;p&gt;By now, you must have understood, namespaces and cgroups help to create isolated environment.
- Namespaces provides isolation of filesystem view, devices, network and processes.
- Cgroups helps to allocate, devices accessibility, and allocate quota to use the devices.&lt;/p&gt;

&lt;p&gt;&lt;img align=&#34;center&#34; src=http://kunalkushwaha.github.io/images/containers.png&gt;&lt;/p&gt;

&lt;h2 id=&#34;is-this-all-sufficient-for-virtualization:b9f02760c1e2afe4297fc7674428ef9f&#34;&gt;Is this all sufficient for Virtualization?&lt;/h2&gt;

&lt;p&gt;No, still security is left. To create secure containers features like Capablities, secomp , SELinux and Apparmor are used for that. These all are integrated with new container solutions like Docker, CoreOS rocket etc.&lt;/p&gt;

&lt;p&gt;Few Container projects worth wating are
- LXC - Linux containers : This is default container hypervisior on all linux based systems. &lt;a href=&#34;https://linuxcontainers.org/&#34;&gt;https://linuxcontainers.org/&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Docker libcontainer:
This is now donated by Docker to Linux foundation and new name will is OpenContainers. &lt;a href=&#34;http://www.opencontainers.org/&#34;&gt;http://www.opencontainers.org/&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;CoreOS - Rocket - &lt;a href=&#34;https://github.com/coreos/rkt&#34;&gt;https://github.com/coreos/rkt&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Redhat&amp;rsquo;s systemd-nspawn. &lt;a href=&#34;http://www.freedesktop.org/software/systemd/man/systemd-nspawn.html&#34;&gt;http://www.freedesktop.org/software/systemd/man/systemd-nspawn.html&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I hope this blog would have help you to understand Linux Containers.&lt;/p&gt;

&lt;p&gt;I will be writing more on current status of linux containers projects in my next blog so stay tuned :)&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Golang Development Environment</title>
      <link>http://kunalkushwaha.github.io/2015/04/27/golang-dev-environment/</link>
      <pubDate>Mon, 27 Apr 2015 22:29:36 +0900</pubDate>
      
      <guid>http://kunalkushwaha.github.io/2015/04/27/golang-dev-environment/</guid>
      <description>

&lt;p&gt;Setting up golang environment is quite simple good docs are already present in golang.org.
&lt;br&gt;But I couldn&amp;rsquo;t find any simple doc, where complete setup with GOROOT and GOPATH along with github is explained.&lt;/p&gt;

&lt;p&gt;So I thought it might be helpful to others too.
&lt;br&gt;My dev environment is ubuntu based &lt;a href=&#34;https://elementary.io/&#34;&gt;ElementryOS &amp;ldquo;Freya&amp;rdquo;&lt;/a&gt;, So it would work on all Ubuntu based distros.&lt;/p&gt;

&lt;h3 id=&#34;golang-installer:22b90498ad19ed8bfadbfc3c440b6be8&#34;&gt;Golang Installer&lt;/h3&gt;

&lt;p&gt;Golang comes with single tar file setup can be downloaded from &lt;a href=&#34;https://golang.org/dl/&#34;&gt;here&lt;/a&gt;
&lt;br&gt;extract the tar file to your /usr/local using below command&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;tar -C /usr/local -xzf go$VERSION.$OS-$ARCH.tar.gz
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;this will install your all go binaries under following dir structure.&lt;/p&gt;

&lt;p&gt;base folder where go is installed.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;/usr/local/go
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;All standard go binaries are in&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;/usr/local/go/bin
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;golang-environment-setup:22b90498ad19ed8bfadbfc3c440b6be8&#34;&gt;Golang environment setup.&lt;/h3&gt;

&lt;p&gt;Now next step is to define golang related environment variable.
&lt;br&gt;There are two important golang Env variables that need to be defined.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;GOROOT : This variable have value, where golang is installed.&lt;/li&gt;
&lt;li&gt;GOPATH : This is like workspace. This folder will be root of all go getable packages and projects.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;br&gt;So you need to create a folder for GOPATH. My fav is ~/go folder.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;kunal@kunal-Aspire-5670:~$ mkdir ~/go
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;So now define GOROOT, GOPATH and append PATH variables.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;export GOROOT=/usr/local/go
export GOPATH=$HOME/go
export PATH=$PATH:$GOROOT/bin:$GOPATH/bin
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Its better to append your ~/.profile file with these 3 lines. So no need to export these variables every time you restart machine.&lt;/p&gt;

&lt;p&gt;After setting environment variables check if everything is set as per expected or not!
&lt;br&gt;Use &amp;ldquo;go env&amp;rdquo; command.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;kunal@kunal-Aspire-5670:~$ go env
GOARCH=&amp;quot;386&amp;quot;
GOBIN=&amp;quot;&amp;quot;
GOCHAR=&amp;quot;8&amp;quot;
GOEXE=&amp;quot;&amp;quot;
GOHOSTARCH=&amp;quot;386&amp;quot;
GOHOSTOS=&amp;quot;linux&amp;quot;
GOOS=&amp;quot;linux&amp;quot;
GOPATH=&amp;quot;/home/kunal/go&amp;quot;
GORACE=&amp;quot;&amp;quot;
GOROOT=&amp;quot;/usr/local/go&amp;quot;
GOTOOLDIR=&amp;quot;/usr/local/go/pkg/tool/linux_386&amp;quot;
CC=&amp;quot;gcc&amp;quot;
GOGCCFLAGS=&amp;quot;-fPIC -m32 -pthread -fmessage-length=0&amp;quot;
CXX=&amp;quot;g++&amp;quot;
CGO_ENABLED=&amp;quot;1&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;verify GOPATH and GOROOT.&lt;/p&gt;

&lt;h3 id=&#34;go-getable:22b90498ad19ed8bfadbfc3c440b6be8&#34;&gt;go getable.&lt;/h3&gt;

&lt;p&gt;One of beauty of golang is &amp;ldquo;go get&amp;rdquo; command.
&lt;br&gt;It automatically downloads the all required packages along with your program from git repo or mercurial.&lt;/p&gt;

&lt;p&gt;Prerequisite to this is you should install git and mercurial both on your machine.
mercurial is required as lot of official libraries of golang is still hosted at google code and it hosted with mercurial.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;kunal@kunal-Aspire-5670:~$ sudo apt-get install mercurial
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;So we are set with all basics, now ready for go getable your code!&lt;/p&gt;

&lt;p&gt;after your go get github.com/&lt;some-go-project&gt;, You will see your ~/go folder have sum folder structure created.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;kunal@kunal-Aspire-5670:~$ ll go
total 32
drwxrwxr-x  6 kunal kunal  4096 Apr 20 20:28 ./
drwx------ 24 kunal kunal 12288 Apr 27 22:45 ../
drwxrwxr-x  2 kunal kunal  4096 Apr 16 03:27 bin/
drwxrwxr-x  3 kunal kunal  4096 Apr 12 21:26 pkg/
drwxrwxr-x  8 kunal kunal  4096 Apr 16 03:24 src/
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;These are folder which will have all your go getable code/packages and binaries.
*bin : folder will have binaries build after you build go project using &amp;ldquo;go build&amp;rdquo;
*pkg : this will have all pakages downloaded due to dependencies of your program. These packages compiled packages.
*src : this will have your source code under folder of source of code like github.com , bitbucket.com, code.google.com etc
e.g&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;kunal@kunal-Aspire-5670:~$ ll go/src/
total 32
drwxrwxr-x  8 kunal kunal 4096 Apr 16 03:24 ./
drwxrwxr-x  6 kunal kunal 4096 Apr 20 20:28 ../
drwxrwxr-x  3 kunal kunal 4096 Apr 16 03:24 bitbucket.org/
drwxrwxr-x  3 kunal kunal 4096 Apr 12 21:28 code.google.com/
drwxrwxr-x 38 kunal kunal 4096 Apr 20 20:05 github.com/
drwxrwxr-x  3 kunal kunal 4096 Apr 12 21:29 golang.org/
drwxrwxr-x  3 kunal kunal 4096 Apr 12 21:29 google.golang.org/
drwxrwxr-x  6 kunal kunal 4096 Apr 16 03:26 gopkg.in/
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;So you are now all set for code/test/ship in golang. Happy Coding :)&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Layman guide to Platform Virtualization</title>
      <link>http://kunalkushwaha.github.io/2015/04/25/layman-guide-to-platform-virtualization/</link>
      <pubDate>Sat, 25 Apr 2015 23:20:04 +0900</pubDate>
      
      <guid>http://kunalkushwaha.github.io/2015/04/25/layman-guide-to-platform-virtualization/</guid>
      <description>

&lt;p&gt;&lt;img align=&#34;center&#34; src=http://kunalkushwaha.github.io/VirtualMachineCartoon.jpg&gt;&lt;/p&gt;

&lt;h3 id=&#34;platform-virtualization:a88864bb2e02cbfffb44963e73e3622a&#34;&gt;Platform Virtualization!&lt;/h3&gt;

&lt;p&gt;Virtualization is not new in Computer World today.
But when I am asked what I am working on, I say &amp;ldquo;Cloud Infrastructure and trying to build a private Cloud Platform!&amp;rdquo;.&lt;/p&gt;

&lt;p&gt;Explaining cloud service is easy but Cloud Infrastructure becomes little difficult.
So I am writing a blog series to explain Cloud Infrastructure and it building blocks.
Hope it will help many others too :)&lt;/p&gt;

&lt;h3 id=&#34;virtualization:a88864bb2e02cbfffb44963e73e3622a&#34;&gt;Virtualization.&lt;/h3&gt;

&lt;p&gt;Though simple meaning of Virtualization is creating virtual version of anything.
But in computer software world everything is already Virtual :).
But computer hardware devices, Network cable etc are real!&lt;/p&gt;

&lt;p&gt;When all these things are created virtually i.e. software simulation of all such hardware its called virtualization!&lt;/p&gt;

&lt;p&gt;But why that is required? I heard Hardware is becoming cheap day by day :-|
These are genuine doubts! indeed hardware is becoming cheap and also performance of capacity wise is improving at much faster rate then ever.&lt;/p&gt;

&lt;p&gt;Also, with increase of hardware capacity, most of hardware are underutilized :O
Yes and this becomes huge concern for business owner, How to utilize best of your hardware.
Second Management of hardware resources is also a addition of cost.&lt;/p&gt;

&lt;p&gt;Using Virtualization both issues can be addressed.
Multiple systems workload is executed on same hardware which result into better utilization,
and Managing multiple systems with software also makes more efficient and easy.&lt;/p&gt;

&lt;h3 id=&#34;how-is-virtualization-is-achieved:a88864bb2e02cbfffb44963e73e3622a&#34;&gt;How is Virtualization is achieved?&lt;/h3&gt;

&lt;p&gt;There are broadly three types of Virtualization Techniques.
&lt;a href=&#34;http://en.wikipedia.org/wiki/Virtualization#Hardware_virtualization&#34;&gt;Wikipedia&lt;/a&gt; has short and crisp definition for all three.&lt;/p&gt;

&lt;p&gt;Here Host OS is the OS which runs on Actual Hardware and Guest OS is running on Virtual Hardware/Machine.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Full virtualization – almost complete simulation of the actual hardware to allow software, which typically consists of a guest operating system, to run unmodified.
&lt;br&gt;e.g. VirtualBox, VMWare Workstations, Parallel for MAC works on full virtualization, No change is required in guest OS&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Partial virtualization – some but not all of the target environment attributes are simulated. As a result, some guest programs may need modifications to run in such virtual environments.
&lt;br&gt;Probably this is first approach to virtualization which lead to full virtualization.
&lt;br&gt;e.g. IBM mainfraim system &lt;a href=&#34;http://en.wikipedia.org/wiki/IBM_M44/44X&#34;&gt;IBM M44/44X&lt;/a&gt; was one of such experimental machine.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Paravirtualization – a hardware environment is not simulated; however, the guest programs are executed in their own isolated domains, as if they are running on a separate system. Guest programs need to be specifically modified to run in this environment.
&lt;br&gt;Paravirtulization is lightweight as compared to full virtualization.
&lt;br&gt;e.g. XEN is based on paravirtualization.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;so-what-we-understood:a88864bb2e02cbfffb44963e73e3622a&#34;&gt;So what we understood!&lt;/h3&gt;

&lt;p&gt;Well, We must have realized with all these techniques, all that is achieved here is Isolation!
Isolation of Hardware, so OS running in Virtual Machine gets a feel all hardware is available for its use.
That is the way all OS are implemented! Exclusive access to hardware.&lt;/p&gt;

&lt;p&gt;But above three methods are not that efficient with Hardware support for Virtualization.
So, CPU also have extra core and support to run the Virtualization code efficently. More you can find on &lt;a href=&#34;http://en.wikipedia.org/wiki/X86_virtualization&#34;&gt;here&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Since Isolation is the key to virtulization, Unix &amp;amp; Linux based OS have few features, which provides Isolation to process.
Features like namespaces, cgroups and chroot.
Utilzing these features, OS level virtualization can be achieved. In linux these are called Containers.&lt;/p&gt;

&lt;p&gt;I will be writing details of containers in my next blog. So stay tuned :)&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Moving to Hugo &amp; github</title>
      <link>http://kunalkushwaha.github.io/2015/03/04/moved-to-github/</link>
      <pubDate>Wed, 04 Mar 2015 14:53:05 +0530</pubDate>
      
      <guid>http://kunalkushwaha.github.io/2015/03/04/moved-to-github/</guid>
      <description>

&lt;p&gt;Started blogging today after few years of gap. Had stopped blogging few years back on &lt;a href=&#34;http://kunalkushwaha.wordpress.com&#34;&gt;wordpress&lt;/a&gt; .&lt;/p&gt;

&lt;p&gt;Blogging is always fun and great way to share your experiences and findings with others.&lt;/p&gt;

&lt;p&gt;Lot of things have changed in last 3-5 years in world of Web Technology, So is the blogging platform too.
While exploring Web Technologies and Golang, I came across the static site genrator and Hugo.&lt;/p&gt;

&lt;p&gt;I found it really powerful tool for blogging as well as Product Documentations.&lt;/p&gt;

&lt;h2 id=&#34;why-not-to-continue-with-wordpress:1dd8e767a925214d802c5a963c76c86a&#34;&gt;Why not to continue with wordpress!&lt;/h2&gt;

&lt;p&gt;I work most of times on linux terminal and &lt;a href=&#34;http://gohugo.io/&#34;&gt;Hugo&lt;/a&gt; with github is seamlessly integrated with  git workflow.
Also, I have complete control over theme and customization. This learning is helpful to me for product documentation too :)&lt;/p&gt;

&lt;p&gt;Going ahead I am hopeful, will write regularly and share intresting findings from work and side projects.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>About Kunal Kushwaha</title>
      <link>http://kunalkushwaha.github.io/about/</link>
      <pubDate>Tue, 03 Mar 2015 17:59:00 +0530</pubDate>
      
      <guid>http://kunalkushwaha.github.io/about/</guid>
      <description>&lt;p&gt;A wannabe Entrepreneur and Experienced Technical Leader in building multiple v1.0 version software&amp;rsquo;s, right from conceptualizing to delivery.&lt;/p&gt;

&lt;p&gt;Have hands on experience in building enterprise storage products, Linux kernel block susbsystem hacking, RAID, High Available systems,  Linux Containers and Docker.&lt;/p&gt;

&lt;p&gt;Few of my area of interests are&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Distributed systems&lt;/li&gt;
&lt;li&gt;Scalability&lt;/li&gt;
&lt;li&gt;Storage systems&lt;/li&gt;
&lt;li&gt;Health Care&lt;/li&gt;
&lt;li&gt;Cloud Technology&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Drop me mail or connect me though social media.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>About Kunal Kushwaha</title>
      <link>http://kunalkushwaha.github.io/about/about/</link>
      <pubDate>Tue, 03 Mar 2015 17:59:00 +0530</pubDate>
      
      <guid>http://kunalkushwaha.github.io/about/about/</guid>
      <description>&lt;p&gt;A wannabe Entrepreneur and Experienced Technical Leader in building multiple v1.0 version software&amp;rsquo;s, right from conceptualizing to delivery.&lt;/p&gt;

&lt;p&gt;Have hands on experience in building enterprise storage products, Linux kernel block susbsystem hacking, RAID, High Available systems,  Linux Containers and Docker.&lt;/p&gt;

&lt;p&gt;Few of my area of interests are&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Distributed systems&lt;/li&gt;
&lt;li&gt;Scalability&lt;/li&gt;
&lt;li&gt;Storage systems&lt;/li&gt;
&lt;li&gt;Health Care&lt;/li&gt;
&lt;li&gt;Cloud Technology&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Drop me mail or connect me though social media.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>